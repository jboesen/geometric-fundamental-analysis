{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import curvlearn as cv\n",
    "from curvlearn.manifolds.manifold import Manifold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from diffpool_helpers.model.diffpool_continuous import TSDiffPool\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import yfinance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import requests\n",
    "from math import floor\n",
    "import dgl\n",
    "from eodhd import APIClient\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_dict = {}\n",
    "\n",
    "files = os.listdir('./symbols_data_raw')\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join('./symbols_data_raw', file))\n",
    "        symbols_dict[file.split('_')[0]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = symbols_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in symbols_dict:\n",
    "    symbols_dict[k].replace('N/A', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol, df in symbols_dict.items():\n",
    "    if isinstance(df.index, pd.PeriodIndex): continue\n",
    "    if df.index.equals(pd.RangeIndex(len(df))): # if index is numbers\n",
    "        df.index = df[\"date\"]\n",
    "    new_index = []  # Store modified indices\n",
    "    for row in df.index:\n",
    "        if isinstance(row, int) or isinstance(row, float) or pd.isna(row):\n",
    "            new_index.append(\"1969Q1\") # quarter string not in dataset to flag for dropping\n",
    "            continue\n",
    "        if row.startswith('Q') and len(row) == 6 and row[2:].isdigit():  \n",
    "            new_index.append(row[2:] + row[0:2])  \n",
    "        else:\n",
    "            if row[:4].isdigit() and row[-1].isdigit(): # check valid format\n",
    "                new_index.append(row)  # append\n",
    "            elif row == \"CY2010\": # found several weird indices in dataset; treat as Q1 of year\n",
    "                new_index.append(\"2010Q1\")\n",
    "            elif row == \"2012CY\":\n",
    "                new_index.append(\"2012Q1\")\n",
    "            elif row == \"2010CY\":\n",
    "                new_index.append(\"2010Q2\")\n",
    "            elif row == \"2019CY\":\n",
    "                new_index.append(\"2019Q1\")\n",
    "            elif row == \"2011CY\":\n",
    "                new_index.append(\"2011Q1\")\n",
    "            elif row == \"2011CY\":\n",
    "                new_index.append(\"\")\n",
    "            else:\n",
    "                print(f\"Invalid index format: {row}. Skipping this row.\")  \n",
    "    df.index = new_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop symbols flagged for dropping\n",
    "for k in symbols_dict: \n",
    "    if \"1969Q1\" in symbols_dict[k].index:\n",
    "        symbols_dict[k] = symbols_dict[k].drop(\"1969Q1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = symbols_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and de-dupe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in symbols_dict:\n",
    "    symbols_dict[k] = symbols_dict[k][~symbols_dict[k].index.isna()]\n",
    "    symbols_dict[k] = symbols_dict[k].sort_index()\n",
    "    dt[k] = dt[k][~dt[k].index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add any missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_rows(df):\n",
    "    \"\"\"\n",
    "    Fills in missing quarters in a DataFrame with indices of the form \"YYYYQq\".\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to fill in.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with missing quarters filled in.\n",
    "    \"\"\"  \n",
    "\n",
    "    min_year = int(df.index.str.slice(0, 4).min())\n",
    "    max_year = int(df.index.str.slice(0, 4).max())\n",
    "    all_quarters = pd.period_range(start=f'{min_year}Q1', end=f'{max_year}Q1', freq='Q-DEC')\n",
    "    try:\n",
    "        df = df.reindex(all_quarters.astype(str)) \n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}. df.index: {df.index}\")\n",
    "        print(f\"Duplicate indices are: {df.index[df.index.duplicated()]}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dt:\n",
    "    dt[k] = add_missing_rows(dt[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_equivalent_columns(df, symbol):\n",
    "    \"\"\"\n",
    "    Merges columns in a DataFrame that can be written as {symbol}:{col1} and {col1},\n",
    "    picking one of the non-null values for each pair.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "        symbol (str): The symbol to look for in the column names.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with merged columns.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the column pairs\n",
    "    column_pairs = {}\n",
    "    \n",
    "    # Iterate through the columns\n",
    "    for col in df.columns:\n",
    "        if col.startswith(f\"{symbol}:\"):\n",
    "            base_col = col[len(f\"{symbol}:\"):]\n",
    "            if base_col in df.columns:\n",
    "                column_pairs[base_col] = col\n",
    "    for base_col, pair_col in column_pairs.items():\n",
    "        df[base_col] = df[[base_col, pair_col]].fillna(method='ffill', axis=1)[base_col]\n",
    "        df = df.drop(pair_col, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dt:\n",
    "    dt[k] = merge_equivalent_columns(dt[k], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute or Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_imputation(df, symbol=\"\"):\n",
    "    if not df.index.equals(pd.RangeIndex(len(df))): # need to reset index\n",
    "        if \"date\" in df.columns:\n",
    "            df = df.drop(\"date\", axis=1) \n",
    "        df.reset_index(inplace=True)\n",
    "    for col in df.columns:\n",
    "        if col == \"date\" or not df[col].isna().any(): continue\n",
    "        if col == \"period\":\n",
    "            df = df.drop(columns=[col])\n",
    "            continue\n",
    "        # impute\n",
    "        if is_numeric_dtype(df[col]) and df[col].isna().any() and df[col].count() / len(df) > 0.75:\n",
    "            nan_indices = df[col].isna()\n",
    "            non_nan_indices = ~nan_indices\n",
    "\n",
    "            l = non_nan_indices[non_nan_indices].index[0]\n",
    "            r = l + 1\n",
    "            df.loc[:l, col] = df.loc[l, col]\n",
    "            last_def = non_nan_indices[non_nan_indices].index[-1]\n",
    "            while r < last_def:\n",
    "                if non_nan_indices[l] and non_nan_indices[r]:\n",
    "                    l += 1\n",
    "                    r += 1\n",
    "                else:\n",
    "                    while r < last_def and nan_indices[r]:\n",
    "                        r += 1\n",
    "                    data_segment = df[col][l:r+1]  # Extract the relevant data segment\n",
    "                    imputation_mean = data_segment.mean()  # Calculate the mean\n",
    "                    df.loc[l + 1:r - 1, col] = imputation_mean  # Fill missing values with the mean\n",
    "                    l, r = r, r + 1\n",
    "            if r < last_def:\n",
    "                df.loc[r:, col] = df.loc[r, col]\n",
    "            # check that imputation worked\n",
    "            if df[col].isna().any():\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            df = df.drop(columns=[col])\n",
    "    if \"index\" in df.columns:\n",
    "        df = df.set_index(\"index\")  \n",
    "    elif \"date\" in df.columns:\n",
    "        df = df.set_index(\"date\") \n",
    "    if df.isnull().values.any():\n",
    "        print(\"Dataframe still has null values.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in symbols_dict:\n",
    "    symbols_dict[k] = sliding_window_imputation(symbols_dict[k], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of columns in each dataframe\n",
    "num_columns = [len(df.columns) for df in symbols_dict.values()]\n",
    "\n",
    "# Plot a histogram\n",
    "plt.hist(num_columns, bins=20)\n",
    "plt.title('Number of Columns in Dataframes')\n",
    "plt.xlabel('Number of Columns')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17186"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = symbols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dataframes with fewer than 10 rows\n",
    "dt = {k: v for k, v in dt.items() if len(v) >= 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = np.concatenate([df.columns for df in dt.values()])\n",
    "counts = Counter(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_above_10 = [v for k, v in counts.items() if v > 2000]\n",
    "col_set = set([k for k, v in counts.items() if v > 2000])\n",
    "\n",
    "plt.hist(counts_above_10)\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_set |= {\"index\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dt = {}\n",
    "for k, df, in dt.items():\n",
    "    intersect_size = len(set(df.columns).intersection(col_set))\n",
    "    if intersect_size > 30:\n",
    "        filtered_dt[k] = df[list(col_set.intersection(df.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in filtered_dt:\n",
    "    filtered_dt[k].index = filtered_dt[k][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./imputed_data'):\n",
    "    os.makedirs('./imputed_data')\n",
    "for symbol, data in filtered_dt.items():\n",
    "    data.to_csv(f'./imputed_data/{symbol}_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "220-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
